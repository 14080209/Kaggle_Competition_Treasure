{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#2018年NIPS-AutoML大赛Part1,AutoFeature\" data-toc-modified-id=\"2018年NIPS-AutoML大赛Part1,AutoFeature-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>2018年NIPS AutoML大赛Part1,AutoFeature</a></span></li><li><span><a href=\"#赛题描述\" data-toc-modified-id=\"赛题描述-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>赛题描述</a></span><ul class=\"toc-item\"><li><span><a href=\"#Task\" data-toc-modified-id=\"Task-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Task</a></span></li><li><span><a href=\"#Scenario\" data-toc-modified-id=\"Scenario-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Scenario</a></span></li><li><span><a href=\"#Phases\" data-toc-modified-id=\"Phases-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Phases</a></span></li><li><span><a href=\"#DataSets\" data-toc-modified-id=\"DataSets-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>DataSets</a></span></li></ul></li><li><span><a href=\"#赛题分析-&amp;--赛题求解\" data-toc-modified-id=\"赛题分析-&amp;--赛题求解-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>赛题分析 &amp;  赛题求解</a></span><ul class=\"toc-item\"><li><span><a href=\"#赛题分析\" data-toc-modified-id=\"赛题分析-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>赛题分析</a></span></li><li><span><a href=\"#赛题求解\" data-toc-modified-id=\"赛题求解-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>赛题求解</a></span></li></ul></li><li><span><a href=\"#自动化的特征工程\" data-toc-modified-id=\"自动化的特征工程-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>自动化的特征工程</a></span><ul class=\"toc-item\"><li><span><a href=\"#针对MV特征的特征工程\" data-toc-modified-id=\"针对MV特征的特征工程-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>针对MV特征的特征工程</a></span><ul class=\"toc-item\"><li><span><a href=\"#MV特征的处理方案\" data-toc-modified-id=\"MV特征的处理方案-4.1.1\"><span class=\"toc-item-num\">4.1.1&nbsp;&nbsp;</span>MV特征的处理方案</a></span></li><li><span><a href=\"#MV特征的例子\" data-toc-modified-id=\"MV特征的例子-4.1.2\"><span class=\"toc-item-num\">4.1.2&nbsp;&nbsp;</span>MV特征的例子</a></span></li><li><span><a href=\"#MV特征的通用方法\" data-toc-modified-id=\"MV特征的通用方法-4.1.3\"><span class=\"toc-item-num\">4.1.3&nbsp;&nbsp;</span>MV特征的通用方法</a></span></li></ul></li><li><span><a href=\"#针对CAT特征的特征工程\" data-toc-modified-id=\"针对CAT特征的特征工程-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>针对CAT特征的特征工程</a></span><ul class=\"toc-item\"><li><span><a href=\"#CAT特征的分类\" data-toc-modified-id=\"CAT特征的分类-4.2.1\"><span class=\"toc-item-num\">4.2.1&nbsp;&nbsp;</span>CAT特征的分类</a></span></li><li><span><a href=\"#CAT特征的通用处理方法&amp;背后含义\" data-toc-modified-id=\"CAT特征的通用处理方法&amp;背后含义-4.2.2\"><span class=\"toc-item-num\">4.2.2&nbsp;&nbsp;</span>CAT特征的通用处理方法&amp;背后含义</a></span></li></ul></li><li><span><a href=\"#针对NUM特征的特征工程\" data-toc-modified-id=\"针对NUM特征的特征工程-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>针对NUM特征的特征工程</a></span><ul class=\"toc-item\"><li><span><a href=\"#NUM特征的分类\" data-toc-modified-id=\"NUM特征的分类-4.3.1\"><span class=\"toc-item-num\">4.3.1&nbsp;&nbsp;</span>NUM特征的分类</a></span></li><li><span><a href=\"#NUM特征的通用处理方法&amp;背后含义\" data-toc-modified-id=\"NUM特征的通用处理方法&amp;背后含义-4.3.2\"><span class=\"toc-item-num\">4.3.2&nbsp;&nbsp;</span>NUM特征的通用处理方法&amp;背后含义</a></span></li></ul></li><li><span><a href=\"#针对TIME特征的特征工程\" data-toc-modified-id=\"针对TIME特征的特征工程-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>针对TIME特征的特征工程</a></span><ul class=\"toc-item\"><li><span><a href=\"#TIME特征的重要性-&amp;-基础应对策略\" data-toc-modified-id=\"TIME特征的重要性-&amp;-基础应对策略-4.4.1\"><span class=\"toc-item-num\">4.4.1&nbsp;&nbsp;</span>TIME特征的重要性 &amp; 基础应对策略</a></span></li><li><span><a href=\"#基于TIME的通用处理方法&amp;背后含义\" data-toc-modified-id=\"基于TIME的通用处理方法&amp;背后含义-4.4.2\"><span class=\"toc-item-num\">4.4.2&nbsp;&nbsp;</span>基于TIME的通用处理方法&amp;背后含义</a></span><ul class=\"toc-item\"><li><span><a href=\"#时间周期特征提取（大家可以直接用pd.datetime这些去直接获取）\" data-toc-modified-id=\"时间周期特征提取（大家可以直接用pd.datetime这些去直接获取）-4.4.2.1\"><span class=\"toc-item-num\">4.4.2.1&nbsp;&nbsp;</span>时间周期特征提取（大家可以直接用pd.datetime这些去直接获取）</a></span></li><li><span><a href=\"#背后含义\" data-toc-modified-id=\"背后含义-4.4.2.2\"><span class=\"toc-item-num\">4.4.2.2&nbsp;&nbsp;</span>背后含义</a></span></li></ul></li></ul></li></ul></li><li><span><a href=\"#小结\" data-toc-modified-id=\"小结-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>小结</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2018年NIPS AutoML大赛Part1,AutoFeature\n",
    "\n",
    "在介绍比赛内容之前我想先先感谢一下我的队友,**李相宁(清华大学&MIT的才子)**,本次比赛的模型的auto部分主要是由队友完成的,自动参数调整以及自动模型集成部分都给我们最终线上的模型带来了较大的稳定性。\n",
    "\n",
    "\n",
    "我平时一般很少会去参加会议相关的比赛，也很少关注会议相关的比赛，之前混得比较多的还是天池和kaggle。知道这个比赛还是在今年6月份毕业之后，研究生老师知道我平时喜欢做比赛，研究学习一些实践的机器学习问题，就提了下这个比赛，我平时做比赛常常喜欢去总结一些通用的东西，一看是关于AutoML的比赛,刚好这个方向最近一直很火，之前也看过一些TPOT:https://github.com/EpistasisLab/tpot, 这些开源包的源码,纯粹是兴趣爱好,所以我最终便打算闲暇时间抽空做一下。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先说一下这个比赛和传统比赛的不同之处,个人认为该算法的不同之处主要在于三个地方：\n",
    "\n",
    "1. 最大的不同之处就是要求算法的**通用性**,因为要求在多个不同的数据集上面都能表现优良，自然算法中所使用的技术就必须是通用的，而不是仅仅适用于某些数据集的；所以每一种方法都是黄金啊，因为用到哪里都是可以提分的......\n",
    "2. 每个数据集都有**时间设置**,也就意味着需要合理考虑时间的分配,用于autofeature的时间,用于模型训练的时间等等,都需要估算好,不然超时就将没有成绩;\n",
    "3. **内存限制在16G**,也就意味着我们不能直接采用暴力枚举特征的方式,因为内存会直接炸掉;如果打算采用暴力特征的方式的话就必须得想好如何进行好的剪枝,将特征的维度控制在一定的范围;\n",
    "\n",
    "很不幸的是，我们算法在Blind Test的时候挂在了内存上面.......所以后面的内容我主要关注在初赛的内容上面。我们团队在初赛的成绩是第二名,复赛GG不扯了。\n",
    "\n",
    "![](./pic/nips_score.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 赛题描述\n",
    "\n",
    "赛题的部分我直接将官网的内容复制到此处,如果有兴趣的朋友可以去下面的链接中直接观看相关的内容。\n",
    "\n",
    "- 比赛链接：https://competitions.codalab.org/competitions/20203#learn_the_details\n",
    "\n",
    "\n",
    "## Task\n",
    "The goal of this challenge is to expose the research community to real world datasets exhibiting the concept drift phenomenon, and under a lifelong ML evaluation scenario. Participants must develop AutoML solutions for dealing with these problems. All datasets are formatted in a uniform way, though the type of features from dataset to dataset might differ (Numerical, Categorical, Multi-valued categorical and time features may be available). The data are provided as preprocessed matrices, so that participants can focus on classification, although participants are welcome to use additional feature transformations / extraction procedures (as long as they do not violate any rule of the challenge). All problems are binary classification tasks and are assessed with the Area Under the ROC Curve (AUC) metric. The considered datasets present, in different degree, the concept drift phenomenon. \n",
    "\n",
    " \n",
    "The identity of the datasets and the type of data is concealed, though their structure (number of patterns, inputs, feature types, etc.) is revealed. The final score in phase 2 (the phase considered for delivering prizes) will be  the average rank of the participants' performance on individual datasets. Winners will be determined by ranking them according to the final score (smallest average rank is best). The overall duration of solutions will be considered as tie-breaking criterion.\n",
    "\n",
    "\n",
    "The tasks are constrained by a time budget, where each dataset has a different (not cumulative) budget. The Codalab platform provides computational resources shared by all participants. Each code submission will be executed in a compute worker with the following characteristics: 4Cores / 16GB Memory / 80G SSD with Ubuntu OS. To ensure the fairness of the evaluation, when a code submission is evaluated, its execution time is limited (details on the time for each dataset are provided in the input data).\n",
    "\n",
    "## Scenario\n",
    "A simulated lifelong ML evaluation scenario is considered (see the figure below). Each dataset is divided into 10 batches of approximately the same number of instances. Instances are chronologically sorted in each batch (and across batches). The code of participants will have access to the data and labels in the first batch (considered a training batch). After that, participants must make predictions for the next i-th batch (the participant’s code will have access to the data of the new batch) and performance will be evaluated. Next, labels for the i-th batch will be revealed to the code, and participants can update their model for making predicitons for ne batch i+1. Your code must implement at least two methods: fitting/training  (using the available data at time i, this method could also store data, perform instance selection, subsampling, etc.), and prediction (your model makes predictions for an unlabeled batch). Please look at the sample code submission included in the Starking kit for guidance on how to design your model/code. Average performance across batches will be used for evaluation of each data set.\n",
    "\n",
    "![](./pic/concept_drifting.png)\n",
    "\n",
    "\n",
    "## Phases\n",
    "The challenge has two phases:\n",
    "\n",
    "- Phase 1: Feedback phase. You can practice on 5 datasets that are of similar nature as the datasets of the second phase. You can make a limited number of submissions, you can download the labeled training data and the unlabeled test set. So you can prepare your code submission at home and submit it later (Please download the starting kit in the files section for instructions on how to reproduce the evaluation framework). Your LAST submission from this phase will be forwarded to the next phase for final testing. \n",
    "- Phase 2: AutoML phase. Your last submission of the previous phase is blind tested on five new datasets. Your code will be trained and tested automatically, without human intervention.\n",
    "During the feedback phase, the results of your last submission on test data are shown on the leaderboard. Prizes will be awarded in Phase 2 only.\n",
    "\n",
    "Important: For Phase 1, we provide you with the first 4 test batches  (in addition to the labeled training batch) so you can easier design your models at home.  For the final phase, only the training batch will be made available to your code initially (then each test batch will be progressively delivered to your code as outlined above).\n",
    "\n",
    "## DataSets\n",
    "| dataset |  time_budget  | train1_data N / P      |  test1  | test2  |    test3  |  test4    |  feat_num| #Instance |\n",
    "| -- | --- | -------------------   | ---    | ---    | ---       | ---      | ---         |-------- |\n",
    "| AA |  3600   | 914308 / 59283 = 15.4 | 850534 / 53665 = 15.849 |  870029 / 53789 = 16.175 |  953304 / 55306 = 17.24 |  827557 / 48704 = 16.99 |  82 | ~10 Million  |\n",
    "| B   | 600  | 154812 / 5243 = 29.53 | 169307 / 5662 = 29.90 | 154833 / 5363 = 28.87 | 148674 / 5360 = 27.74 | 160980 / 5546 = 29.03 | 25 | ~1.9 Million |\n",
    "| C   | 1200  | 180221 / 125 = 1441.768 | 193234 / 126 = 1533.60 | 131488 / 86 = 1528.83 | 159591 / 80 = 1994.89 | 183121 / 72 = 2543.35 | 79 | ~2 Million    |\n",
    "| D   | 600 | 145927 / 7115 = 20.5 | 145500 / 7624 = 19.08 | 150578 / 7274 = 20.70 | 146968 / 6965 = 21.10 | 156298 / 7531 = 20.75 | 76 | ~1.5 Million |\n",
    "| E   |  1800 | 1598983 / 26120 = 61.21 | 1718113 / 28141 = 61.05 | 1737149 / 27799 = 62.49 | 1785902 / 29350 = 60.85 | 1753589 / 28195 = 62.20 |34 | ~17 Million  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 赛题分析 &  赛题求解\n",
    " ## 赛题分析\n",
    "本次赛题的难处可以分为两大块,\n",
    "\n",
    "1. 如何解决当前epoch的问题,即如果利用一个数据集;\n",
    "2. 如何利用好前面epoch的数据,也就是concept drift的问题.\n",
    " \n",
    "因为我关注的是第一块,也就是automl的部分,至于concept drift这个问题的研究有很多,但是后面的部分我就不提了,最简单暴力提分的方法就是保留前面数据集中带有标志性的样本,本次赛题因为限制内存,所以我们没有采样这个方法......线下测试的时候该方法确实是分数暴涨的。当然还有很多很好的方法，具体地可以参考论文。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 赛题求解\n",
    "\n",
    "抛开concept drift这个不提,假设我们手上就只有一个epoch的数据，我们该如何在此情况下面拿到高分。我们团队将这一模块简单的分为三部分，\n",
    "\n",
    "1. <font color=red>auto feature engineering**(提升80%)**;</font>\n",
    "2. <font color=red>auto model selection**(提升10%)**;</font>\n",
    "3. <font color=red>auto hyperpara tuning**(提升10%)**.</font>\n",
    "\n",
    "\n",
    "上面的提升是相对的，在五个数据集上面的平均,因为有的数据集受参数影响较大,例如C数据集,有的数据集受模型的影响较大(有的数据集xgb效果好,有的数据集lgb的效果好),如何在有限的时间内快速地选出适合的模型以及相对较好的模型参数也是非常大的一个挑战。本篇文章我会简单的阐述各类特征的一些适用的特征工程方案。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自动化的特征工程\n",
    "\n",
    "因为本次比赛的特征主要由四类特征组成, Multivalue(多值特征);Time(时间特征);CAT(类别特征);NUM(数值特征);此次比赛我们线上一共采用了6套特征工程;因为很多有用的特征工程线下提分,但是线上是超时的,最终无奈只用了6套;下面我就简单阐述几套通用的特征工程,希望对大家有所启发。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 针对MV特征的特征工程\n",
    "\n",
    "### MV特征的处理方案\n",
    "MV特征,中文是多值特征,也就是由一堆加密数值表示的特征,平时处理此类特征的时候，方法不下于10种，可以结合时间特征，采用集合操作进行处理；可以当做某类产品展开处理；也可能这上百万的多值中其实只有10个属性，我们可以细细分析业务转化为少量维度的特征等。\n",
    "\n",
    "### MV特征的例子\n",
    "而MV特征出现的例子也很多,例如在购物推荐中，每一个多值特征可能表示用户所购买的产品的情况;在一些用户欺诈的问题中,多值特征又可能表示用户的一些属性,例如：男，39岁等等信息。\n",
    "\n",
    "### MV特征的通用方法\n",
    "因为此处我们不清楚具体是哪一类问题，所以我们处理此类特征的时候需要找出通用的能提分的方法。\n",
    "\n",
    "sample1: 123,1245,124,012\n",
    "\n",
    "sample2: 1234,232,124\n",
    "\n",
    "...\n",
    "\n",
    "据我所知，处理MV特征的通用方法有三种,此处我介绍一种最为常见的方法,就是采用CounterVector对每一个值进行处理,也可以加threshold进行限制，最后得到一个稀疏的特征，这种方法很通用，在国内的<font color=red>讯飞推荐比赛,详见datacastle </font>,冠军选手就是采用的此类方法的。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 针对CAT特征的特征工程\n",
    "###  CAT特征的分类\n",
    "CAT特征,中文是类别特征,类别特征的处理方法相比MV就更多了，在处理CAT特征的时候，一般我们需要将CAT特征分为两块,\n",
    "\n",
    "1. 拥有相对大小的CAT特征,例如年龄段;\n",
    "2. 没有相对大小的CAT特征,例如颜色等。\n",
    "\n",
    "而针对上面的特征，所需要采用的处理方式又会有很大的区分，下面我们就简单阐述一种稳定提分的处理方法以及其背后的含义。\n",
    "\n",
    "\n",
    "### CAT特征的通用处理方法&背后含义\n",
    "\n",
    "一般处理CAT特征,我们可以通过下面的方式进行,我将其称作是<font color=red>**一阶count特征**</font>,因为它用到最简单的value_counts进行特征的统计，这个特征最常见的情况就是音乐推荐或者大V的定位等。\n",
    "\n",
    "- 一般一个值出现多次，那么在音乐推荐问题中，这个count特征就可以表示它的流行度；\n",
    "\n",
    "- 而如果一个人被搜索多次，那么这个人往往是网红人物或者某个大V.\n",
    "\n",
    "- 同样的，如果一个菜被购买了多次，那么证明这个菜也是非常畅销"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### first order count features #############\n",
    "dic = data[cat].value_counts().to_dict()\n",
    "data[cat+'_count'] = data[cat].apply(lambda x:dic[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 针对NUM特征的特征工程\n",
    "\n",
    "###  NUM特征的分类\n",
    "\n",
    "NUM特征一般可以分为两类,\n",
    "1. 相同物理意义的NUM特征;\n",
    "2. 不同物理意义的NUM特征.\n",
    "\n",
    "相同物理意义，我们一般指相同大小的一些量，举例来说不同时刻的温度值，不同月份的贷款值等，这些量纲直接的加,减,均值等，都有很强的物理意义，往往也是非常好的特征。\n",
    "\n",
    "不同物理意义的NUM特征，我们一般指不同大小的一些量，例如体重，金钱，眼睛度数等，这些量的加减往往没有什么物理意义。\n",
    "\n",
    "\n",
    "### NUM特征的通用处理方法&背后含义\n",
    "\n",
    "NUM特征最常见的也经常在kaggle的匿名比赛中看到的就是加减乘除,具体的如下，一般大家会采用排列组合的方法进行提取，在kaggle 4年前的一个比赛，现役排行第三的kaggler就给出了两个特征之间相除得到的一个极强的特征，并采用该特征将auc提升到了一个很高的分数。\n",
    "\n",
    "- NUM1 + NUM2\n",
    "- NUM1 * NUM2\n",
    "- NUM1 / NUM2\n",
    "- NUM1 - NUM2\n",
    "- (NUM1 - NUM2) /NUM3\n",
    "- (NUM1 + NUM2) /NUM3\n",
    "- (NUM1 - NUM2) * NUM3\n",
    "- (NUM1 + NUM2) * NUM3\n",
    "- ......"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  针对TIME特征的特征工程\n",
    "\n",
    "### TIME特征的重要性 & 基础应对策略\n",
    "\n",
    "一般如果出现拥有相对大小关系的TIME特征,我们必须做的是,验证时间对我们的验证是否有较强的影响，如果有较强的影响，那么我们就可以采用基于时间的stacking策略,如果影响不大,那么我们可以采用简单的5折Model预测。\n",
    "\n",
    "关于基于时间的stacking操作，大家可以到三年前Avazu的比赛中去找到，我个人验证，这个比赛5个数据集采用基于时间的stacking才做线下都会有0.015左右的提升,至少说明初赛的5个数据集都是受到时序影响的。\n",
    "\n",
    "\n",
    "### 基于TIME的通用处理方法&背后含义\n",
    "\n",
    "TIME特征不仅对我们模型的构建，包括特征的提取，验证集的设计以及集成策略有着非常大的影响同时也可以提取很多有用的特征，那么针对TIME特征,我们可以用什么方法对其进行提取的，做过时间处理问题的朋友都知道基于时间的问题最经典的有三大属性，趋势性，季节性以及周期性，而周期性的特征往往是我们可以从TIME中直接得到的\n",
    "\n",
    "#### 时间周期特征提取（大家可以直接用pd.datetime这些去直接获取）\n",
    "典型的周期特征有下面四个,大家都可以直接拿到：\n",
    "- 月\n",
    "- 日\n",
    "- 星期几\n",
    "- 几时\n",
    "\n",
    "#### 背后含义\n",
    "因为基于TIME可以直接拿到的是周期特征,它背后的含义就更简单了,简单的说很多人喜欢月底购物，很多人喜欢周五晚上看电影来放松等等，那么固定的属性特征就能很好的反映这些情况\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 小结\n",
    "\n",
    "本篇文章给出了每类特征的一些简单的处理方法，包括每一类特征的背后可能出现的场景，以及针对此类问题能稳定拿到的得分技巧，往往都能提非常高的分数。\n",
    "\n",
    "在下一节我会介绍此次AutoML比赛我们特征表示的内容，以及模型自动选择&调参的部分(模型部分主要是队友设计的),感兴趣的可以去听队友的talk.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
