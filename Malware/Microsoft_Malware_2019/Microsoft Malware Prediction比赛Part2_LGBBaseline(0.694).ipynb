{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#工具包-&amp;-数据导入\" data-toc-modified-id=\"工具包-&amp;-数据导入-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>工具包 &amp; 数据导入</a></span><ul class=\"toc-item\"><li><span><a href=\"#开源工具包导入\" data-toc-modified-id=\"开源工具包导入-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>开源工具包导入</a></span></li><li><span><a href=\"#自定义工具包导入\" data-toc-modified-id=\"自定义工具包导入-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>自定义工具包导入</a></span></li><li><span><a href=\"#数据导入\" data-toc-modified-id=\"数据导入-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>数据导入</a></span><ul class=\"toc-item\"><li><span><a href=\"#原始数据读取\" data-toc-modified-id=\"原始数据读取-1.3.1\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span>原始数据读取</a></span></li><li><span><a href=\"#降低数据内存\" data-toc-modified-id=\"降低数据内存-1.3.2\"><span class=\"toc-item-num\">1.3.2&nbsp;&nbsp;</span>降低数据内存</a></span></li></ul></li></ul></li><li><span><a href=\"#特征工程\" data-toc-modified-id=\"特征工程-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>特征工程</a></span><ul class=\"toc-item\"><li><span><a href=\"#所有object特征进行labelencoder\" data-toc-modified-id=\"所有object特征进行labelencoder-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>所有object特征进行labelencoder</a></span></li><li><span><a href=\"#frequency编码\" data-toc-modified-id=\"frequency编码-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>frequency编码</a></span></li><li><span><a href=\"#数据合并\" data-toc-modified-id=\"数据合并-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>数据合并</a></span></li></ul></li><li><span><a href=\"#模型训练&amp;测试\" data-toc-modified-id=\"模型训练&amp;测试-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>模型训练&amp;测试</a></span><ul class=\"toc-item\"><li><span><a href=\"#全量LGB\" data-toc-modified-id=\"全量LGB-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>全量LGB</a></span></li><li><span><a href=\"#模型训练\" data-toc-modified-id=\"模型训练-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>模型训练</a></span></li><li><span><a href=\"#模型测试\" data-toc-modified-id=\"模型测试-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>模型测试</a></span></li><li><span><a href=\"#实验结果(LB:0.69397,-PB：0.63574-868/2426)\" data-toc-modified-id=\"实验结果(LB:0.69397,-PB：0.63574-868/2426)-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>实验结果(LB:0.69397, PB：0.63574 868/2426)</a></span></li></ul></li><li><span><a href=\"#小结\" data-toc-modified-id=\"小结-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>小结</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 工具包 & 数据导入\n",
    "## 开源工具包导入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/zjpy36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "## 数据工具包\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "from tqdm import tqdm \n",
    "from tqdm import tqdm_notebook\n",
    "## 字符串处理工具包\n",
    "\n",
    "import string\n",
    "import re\n",
    "import gensim\n",
    "from collections import Counter\n",
    "import pickle\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.preprocessing import text, sequence \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from functools import partial\n",
    "import joblib\n",
    "\n",
    "import os \n",
    "import gc\n",
    "from scipy.sparse import vstack  \n",
    "import time \n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 自定义工具包导入\n",
    "- 该工具包主要用于降低数据的内存消耗,但是在使用时需要注意精度溢出的问题\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm \n",
    "class _Data_Preprocess:\n",
    "    def __init__(self):\n",
    "        self.int8_max =  np.iinfo(np.int8).max\n",
    "        self.int8_min =  np.iinfo(np.int8).min\n",
    "        \n",
    "        self.int16_max =  np.iinfo(np.int16).max\n",
    "        self.int16_min =  np.iinfo(np.int16).min\n",
    "      \n",
    "        self.int32_max =  np.iinfo(np.int32).max\n",
    "        self.int32_min =  np.iinfo(np.int32).min\n",
    "      \n",
    "        self.int64_max =  np.iinfo(np.int64).max\n",
    "        self.int64_min =  np.iinfo(np.int64).min\n",
    "        \n",
    "        self.float16_max =  np.finfo(np.float16).max\n",
    "        self.float16_min =  np.finfo(np.float16).min\n",
    "        \n",
    "        self.float32_max =  np.finfo(np.float32).max\n",
    "        self.float32_min =  np.finfo(np.float32).min\n",
    "      \n",
    "        self.float64_max =  np.finfo(np.float64).max\n",
    "        self.float64_min =  np.finfo(np.float64).min\n",
    "         \n",
    "    \n",
    "    '''\n",
    "    function: _get_type(self,min_val, max_val, types)\n",
    "    \n",
    "       get the correct types that our columns can trans to\n",
    "    \n",
    "    '''\n",
    "    def _get_type(self,min_val, max_val, types):\n",
    "        if types == 'int':\n",
    "            if max_val <= self.int8_max and min_val >= self.int8_min:\n",
    "                return np.int8\n",
    "            elif max_val <= self.int16_max  <= max_val and min_val >= self.int16_min:\n",
    "                return np.int16\n",
    "            elif max_val <= self.int32_max and min_val >= self.int32_min:\n",
    "                return np.int32\n",
    "            return None\n",
    "            \n",
    "        elif types == 'float':\n",
    "            if max_val <=  self.float16_max and min_val >= self.float16_min :\n",
    "                return np.float16\n",
    "            if max_val <=  self.float32_max and min_val >= self.float32_min :\n",
    "                return np.float32\n",
    "            if max_val <=  self.float64_max and min_val >= self.float64_min:\n",
    "                return np.float64 \n",
    "            return None\n",
    "    '''\n",
    "    \n",
    "    function: _memory_process(self,df) \n",
    "       column data types trans, to save more memory\n",
    "    '''\n",
    "    def _memory_process(self,df):\n",
    "        init_memory = df.memory_usage().sum() / 1024**2 / 1024\n",
    "        print('Original data occupies {} GB memory.'.format(init_memory))\n",
    "        df_cols = df.columns\n",
    "        \n",
    "        for col in tqdm(df_cols):\n",
    "            try:\n",
    "                if 'float' in str(df[col].dtypes): \n",
    "                    max_val = df[col].max()\n",
    "                    min_val = df[col].min()\n",
    "                    trans_types = self._get_type(min_val,max_val,'float')\n",
    "                    if trans_types is not None: \n",
    "                        df[col] = df[col].astype(trans_types)\n",
    "                elif 'int' in str(df[col].dtypes):  \n",
    "                    max_val = df[col].max()\n",
    "                    min_val = df[col].min()\n",
    "                    trans_types = self._get_type(min_val,max_val,'int')\n",
    "                    if trans_types is not None:  \n",
    "                        df[col] = df[col].astype(trans_types) \n",
    "            except:\n",
    "                print(' Can not do any process for column, {}.'.format(col))\n",
    "        afterprocess_memory = df.memory_usage().sum() / 1024**2 / 1024\n",
    "        print('After processing, the data occupies {} GB memory.'.format(afterprocess_memory))\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 数据导入\n",
    " ### 原始数据读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/data/Data_JieZhang/MicroMalware/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 47s, sys: 12.8 s, total: 2min 59s\n",
      "Wall time: 3min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train = pd.read_csv(path + 'train.csv')\n",
    "test = pd.read_csv(path + 'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['HasDetections'] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test = pd.concat([train,test],ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 降低数据内存\n",
    "- 因为数据内存较大,如果机器内存较小,可以考虑先对数据的内存进行处理,当然还有一种更加方便的策略,就是在读取数据的时候就指定每列特征是int还是float型,只是那样得比较细心,各位可以按照自己的喜好进行处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_preprocess = _Data_Preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/83 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data occupies 10.373466446995735 GB memory.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [00:16<00:00,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After processing, the data occupies 5.749150112271309 GB memory.\n",
      "CPU times: user 14.9 s, sys: 1.89 s, total: 16.8 s\n",
      "Wall time: 16.7 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_test = data_preprocess._memory_process(train_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特征工程\n",
    "## 所有object特征进行labelencoder\n",
    "- 为了不损失object特征的信息,我们对所有的object特征进行labelencoder,从而将object特征转化为整型,方便用于模型的训练&测试.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 ms, sys: 0 ns, total: 4 ms\n",
      "Wall time: 4.44 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "object_cols = list(train_test.dtypes[train_test.dtypes == 'object'].index)\n",
    "object_cols.remove('MachineIdentifier') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf1cf4dd6cc14241b50685bdc6e05df8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=29), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lbencoding_fea = pd.DataFrame()\n",
    "lbencoding_fea['MachineIdentifier'] = train_test['MachineIdentifier'].values\n",
    "for col in tqdm_notebook(object_cols):\n",
    "    lbencoding_fea[col + '_labelcoder'] = LabelEncoder().fit_transform(train_test[col].astype(str).fillna('NAN').values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [00:06<00:00, 12.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.19 s, sys: 1.59 s, total: 6.78 s\n",
      "Wall time: 6.75 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for col in tqdm(train_test.columns):\n",
    "    if col!='MachineIdentifier' and col + '_labelcoder' in lbencoding_fea.columns:\n",
    "        train_test[col] = lbencoding_fea[col+ '_labelcoder' ].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 降低数据的内存使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data occupies 3.749445751309395 GB memory.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:07<00:00,  3.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After processing, the data occupies 0.7186438292264938 GB memory.\n",
      "CPU times: user 6.05 s, sys: 1.9 s, total: 7.94 s\n",
      "Wall time: 7.91 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lbencoding_fea = data_preprocess._memory_process(lbencoding_fea) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## frequency编码\n",
    "- <font color=red>frequency编码在此处可以认为是一种流行度的编码,如果一个东西出现的越多,比如浏览器中Chrome出现的非常多,也就是说安装Chrome的用户非常多,那么通过frequency编码就可以很好的反映出Chrome的流行度使用量较高的信息。同样地,对于其他的版本信息也是一样的。</font>\n",
    "- 在微软的比赛中,frequency编码反映的另外一种信息是,如果某个产品越加流行,那么该产品的利益价值就越高,黑客可能就更加喜欢攻击此类产品\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_nunique = train_test.nunique()\n",
    "A_cnt_features = [col for col in train_test_nunique.index if train_test_nunique.loc[col] > 5 and col!='MachineIdentifier']\n",
    "len(A_cnt_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ProductName',\n",
       " 'EngineVersion',\n",
       " 'AppVersion',\n",
       " 'AvSigVersion',\n",
       " 'RtpStateBitfield',\n",
       " 'DefaultBrowsersIdentifier',\n",
       " 'AVProductStatesIdentifier',\n",
       " 'AVProductsInstalled',\n",
       " 'AVProductsEnabled',\n",
       " 'CountryIdentifier',\n",
       " 'CityIdentifier',\n",
       " 'OrganizationIdentifier',\n",
       " 'GeoNameIdentifier',\n",
       " 'LocaleEnglishNameIdentifier',\n",
       " 'OsVer',\n",
       " 'OsBuild',\n",
       " 'OsSuite',\n",
       " 'OsPlatformSubRelease',\n",
       " 'OsBuildLab',\n",
       " 'SkuEdition',\n",
       " 'IeVerIdentifier',\n",
       " 'SmartScreen',\n",
       " 'UacLuaenable',\n",
       " 'Census_MDC2FormFactor',\n",
       " 'Census_OEMNameIdentifier',\n",
       " 'Census_OEMModelIdentifier',\n",
       " 'Census_ProcessorCoreCount',\n",
       " 'Census_ProcessorManufacturerIdentifier',\n",
       " 'Census_ProcessorModelIdentifier',\n",
       " 'Census_PrimaryDiskTotalCapacity',\n",
       " 'Census_SystemVolumeTotalCapacity',\n",
       " 'Census_TotalPhysicalRAM',\n",
       " 'Census_ChassisTypeName',\n",
       " 'Census_InternalPrimaryDiagonalDisplaySizeInInches',\n",
       " 'Census_InternalPrimaryDisplayResolutionHorizontal',\n",
       " 'Census_InternalPrimaryDisplayResolutionVertical',\n",
       " 'Census_PowerPlatformRoleName',\n",
       " 'Census_InternalBatteryType',\n",
       " 'Census_InternalBatteryNumberOfCharges',\n",
       " 'Census_OSVersion',\n",
       " 'Census_OSBranch',\n",
       " 'Census_OSBuildNumber',\n",
       " 'Census_OSBuildRevision',\n",
       " 'Census_OSEdition',\n",
       " 'Census_OSSkuName',\n",
       " 'Census_OSInstallTypeName',\n",
       " 'Census_OSInstallLanguageIdentifier',\n",
       " 'Census_OSUILocaleIdentifier',\n",
       " 'Census_OSWUAutoUpdateOptionsName',\n",
       " 'Census_GenuineStateName',\n",
       " 'Census_ActivationChannel',\n",
       " 'Census_FlightRing',\n",
       " 'Census_FirmwareManufacturerIdentifier',\n",
       " 'Census_FirmwareVersionIdentifier',\n",
       " 'Wdft_RegionIdentifier']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_cnt_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb73af19a47d4d2d93e855ce9f6a18e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=55), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "frequency_fea = pd.DataFrame()\n",
    "frequency_fea['MachineIdentifier'] = train_test['MachineIdentifier'].values\n",
    "\n",
    "for col in tqdm_notebook(A_cnt_features):\n",
    "    train_test[col]             = train_test[col].fillna(-999)\n",
    "    frequency_fea[col + '_cnt'] = train_test[col].map(train_test[col].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 降低数据的内存使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/56 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data occupies 6.998965337872505 GB memory.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56/56 [00:13<00:00,  3.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After processing, the data occupies 3.5619734674692154 GB memory.\n",
      "CPU times: user 12 s, sys: 1.9 s, total: 13.9 s\n",
      "Wall time: 13.8 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "frequency_fea = data_preprocess._memory_process(frequency_fea) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据合并"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 12s, sys: 14.2 s, total: 1min 26s\n",
      "Wall time: 1min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "merge_cols = ['MachineIdentifier','IsBeta', 'RtpStateBitfield', 'IsSxsPassiveMode','DefaultBrowsersIdentifier', 'AVProductStatesIdentifier',\n",
    "       'AVProductsInstalled', 'AVProductsEnabled', 'HasTpm', 'CountryIdentifier', 'CityIdentifier', 'OrganizationIdentifier',\n",
    "       'GeoNameIdentifier', 'LocaleEnglishNameIdentifier', 'OsBuild','OsSuite', 'IsProtected', 'AutoSampleOptIn', 'SMode', 'IeVerIdentifier',\n",
    "       'Firewall', 'UacLuaenable', 'Census_OEMNameIdentifier','Census_OEMModelIdentifier', 'Census_ProcessorCoreCount',\n",
    "       'Census_ProcessorManufacturerIdentifier','Census_ProcessorModelIdentifier', 'Census_PrimaryDiskTotalCapacity',\n",
    "       'Census_SystemVolumeTotalCapacity', 'Census_HasOpticalDiskDrive',\n",
    "       'Census_TotalPhysicalRAM','Census_InternalPrimaryDiagonalDisplaySizeInInches','Census_InternalPrimaryDisplayResolutionHorizontal',\n",
    "       'Census_InternalPrimaryDisplayResolutionVertical','Census_InternalBatteryNumberOfCharges', 'Census_OSBuildNumber',\n",
    "       'Census_OSBuildRevision', 'Census_OSInstallLanguageIdentifier','Census_OSUILocaleIdentifier', 'Census_IsPortableOperatingSystem',\n",
    "       'Census_IsFlightingInternal', 'Census_IsFlightsDisabled','Census_ThresholdOptIn', 'Census_FirmwareManufacturerIdentifier',\n",
    "       'Census_FirmwareVersionIdentifier', 'Census_IsSecureBootEnabled', 'Census_IsWIMBootEnabled', 'Census_IsVirtualDevice',\n",
    "       'Census_IsTouchEnabled', 'Census_IsPenCapable','Census_IsAlwaysOnAlwaysConnectedCapable', 'Wdft_IsGamer', 'Wdft_RegionIdentifier', 'HasDetections']\n",
    "train_test_data = train_test[merge_cols].merge(lbencoding_fea, on ='MachineIdentifier', how='left')\n",
    "train_test_data = train_test_data.merge(frequency_fea, on ='MachineIdentifier', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = train_test_data.loc[train_test_data['HasDetections'].isin([0,1]) == True]\n",
    "test_set  = train_test_data.loc[train_test_data['HasDetections'].isin([0,1]) == False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型训练&测试\n",
    "\n",
    "- 因为此次数据的量较大,采用5折的LGB训练虽然可以取得不错的成绩,但是迭代的过程较慢,而且数据量非常的大,不是一个很好的选择,当然如果大家希望在比赛过程中获得更好的成绩,建议大家采用N-fold的训练测试的方法。\n",
    "\n",
    "## 全量LGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _single_lgbmodel(df, df_label):\n",
    "    importances = pd.DataFrame()\n",
    "    lgb_params = {'objective':'binary', \"boosting\": \"gbdt\", 'learning_rate': 0.03, 'max_depth': -1, \n",
    "     \"feature_fraction\": 0.8, \"bagging_freq\": 1, \"bagging_fraction\": 0.8 , \"bagging_seed\": 11, 'n_estimators': 2500,\n",
    "     \"metric\": 'auc', \"lambda_l1\": 0.1, 'num_leaves': 256, 'min_data_in_leaf': 50, \"verbose\": 1, \"num_threads\": 50}\n",
    "      \n",
    "    \n",
    "    model = lgb.LGBMClassifier(**lgb_params)\n",
    "    model.fit(df, df_label, eval_set=[(df, df_label)], verbose = 250, eval_metric ='auc')     \n",
    "\n",
    "    imp_df = pd.DataFrame()\n",
    "    imp_df['feature'] = df.columns\n",
    "    imp_df['gain']    = model.feature_importances_\n",
    "        \n",
    "    gc.collect()\n",
    "    return model,imp_df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cols = [col for col in train_test_data.columns if col not in ['MachineIdentifier','HasDetections','isval']]\n",
    "train_label = 'HasDetections'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[250]\ttraining's auc: 0.734275\n",
      "[500]\ttraining's auc: 0.743315\n",
      "[750]\ttraining's auc: 0.747874\n",
      "[1000]\ttraining's auc: 0.751305\n",
      "[1250]\ttraining's auc: 0.7543\n",
      "[1500]\ttraining's auc: 0.75718\n",
      "[1750]\ttraining's auc: 0.75987\n",
      "[2000]\ttraining's auc: 0.76242\n",
      "[2250]\ttraining's auc: 0.764876\n",
      "[2500]\ttraining's auc: 0.767355\n",
      "CPU times: user 2d 15h 27s, sys: 1h 53min 58s, total: 2d 16h 54min 25s\n",
      "Wall time: 1h 58min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model, model_imp = _single_lgbmodel(train_set[train_cols], train_set[train_label].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict_proba(test_set[train_cols])[:,1]\n",
    "test_set['HasDetections'] = pred\n",
    "test_set['HasDetections'] = test_set['HasDetections']\n",
    "test_set[['MachineIdentifier','HasDetections']].to_csv('baseline_labelencode_frequency.csv',index = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实验结果(LB:0.69397, PB：0.63574 868/2426)\n",
    "![](./pic/baseline_score.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 小结\n",
    "\n",
    "在本篇文章中,我们给出了两种处理类别特征的常用方案：\n",
    "\n",
    "1. labelencoder;\n",
    "2. frequency encoder.\n",
    "\n",
    "最后为了方便我们采用全量lgb对我们的数据进行训练&测试,在下一节的内容中,我们会在本篇文章的基础上进一步提升我们模型的性能。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
